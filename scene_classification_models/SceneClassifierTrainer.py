import torch
from torch import nn, optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
import os
from pathlib import Path
import json
from typing import Dict, List, Tuple, Optional


class SceneClassifierTrainer:
    """COCåœºæ™¯åˆ†ç±»å™¨è®­ç»ƒç±»"""
    
    def __init__(self, 
                 data_dir: str = "../scene_classification_dataset",
                 model_save_path: str = "BBAutoAttack_scene_classifier.pt",
                 config_save_path: str = "BBAutoAttack_scene_classifier.json",
                 batch_size: int = 16,
                 img_size: int = 224,
                 learning_rate: float = 0.001):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            data_dir: æ•°æ®é›†ç›®å½•
            model_save_path: æ¨¡å‹ä¿å­˜è·¯å¾„
            config_save_path: é…ç½®æ–‡ä»¶ä¿å­˜è·¯å¾„
            batch_size: æ‰¹æ¬¡å¤§å°
            img_size: å›¾åƒå°ºå¯¸
            learning_rate: å­¦ä¹ ç‡
        """
        self.data_dir = Path(data_dir)
        self.model_save_path = model_save_path
        self.config_save_path = config_save_path
        self.batch_size = batch_size
        self.img_size = img_size
        self.learning_rate = learning_rate
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[INFO] ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆå§‹åŒ–å±æ€§
        self.model = None
        self.train_loader = None
        self.val_loader = None
        self.class_names = []
        self.num_classes = 0
        
        # è®­ç»ƒå†å²
        self.training_history = {
            "train_loss": [],
            "train_acc": [],
            "val_loss": [],
            "val_acc": []
        }
    
    def _get_transforms(self) -> Tuple[transforms.Compose, transforms.Compose]:
        """
        æ„å»ºä¸¤ä¸ªå›¾åƒå¤„ç†çš„â€œæµæ°´çº¿â€ï¼š
        - è®­ç»ƒé›†ä¼šåšç¿»è½¬ã€æ—‹è½¬ã€å˜äº®ç­‰å¢å¼ºæ“ä½œ
        - éªŒè¯é›†åªåšåŸºç¡€çš„ç¼©æ”¾å’Œå½’ä¸€åŒ–

        è¿™äº›æ“ä½œä¼šåœ¨å›¾ç‰‡å–‚ç»™æ¨¡å‹ä¹‹å‰è‡ªåŠ¨æ‰§è¡Œï¼ˆGPTå†™çš„ï¼Œä¸çŸ¥é“è¿™å¥è¯å•¥æ„æ€ï¼‰
        """
        # transforms.Compose(...) è¿™ä¸ªå†™æ³•æ˜¯ PyTorch çš„å›¾åƒé¢„å¤„ç†pipelineçš„å·¥å…·ã€‚
        # ä¼ è¿›å»ä¸€ä¸ªå˜æ¢åˆ—è¡¨ [...]ï¼Œä¼šè‡ªåŠ¨æŒ‰é¡ºåºæ‰§è¡Œæ¯ä¸ªå˜æ¢ï¼Œ
        # è°ƒç”¨ Compose å¯¹è±¡å°±ç­‰äºä¾æ¬¡æ‰§è¡Œå…¨éƒ¨æ­¥éª¤ã€‚
        train_transform = transforms.Compose([
            transforms.Resize((self.img_size, self.img_size)),
            transforms.RandomHorizontalFlip(p=0.3),
            transforms.RandomRotation(degrees=10),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        val_transform = transforms.Compose([
            transforms.Resize((self.img_size, self.img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        return train_transform, val_transform

    def load_data(self, train_split: float = 0.8) -> bool:
        """
        è¯»å–å›¾ç‰‡æ•°æ®é›†ï¼Œå¹¶æŠŠå®ƒåˆ‡åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
        åŒæ—¶è®¾ç½®å›¾åƒé¢„å¤„ç†æ“ä½œï¼ˆæ¯”å¦‚ç¼©æ”¾ã€ç¿»è½¬ç­‰ï¼‰
        æœ€åè¿”å›ä¸¤ä¸ª DataLoaderï¼Œä¾›æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä½¿ç”¨
        
        Args:
            train_split: è®­ç»ƒé›†æ¯”ä¾‹
            train_split=0.8 è¡¨ç¤º 80% çš„å›¾ç‰‡ç”¨æ¥è®­ç»ƒï¼Œ20% éªŒè¯ï¼ˆé»˜è®¤è®¾ç½®ï¼‰ã€‚
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½æ•°æ®
        """
        try:
            train_transform, val_transform = self._get_transforms()
            
            # åŠ è½½æ•°æ®é›†ï¼Œè¿™è¡Œéå¸¸å…³é”®ï¼šä½¿ç”¨ PyTorch è‡ªå¸¦çš„ ImageFolder ç±»ä»æ–‡ä»¶å¤¹è¯»å–å›¾ç‰‡ï¼Œæ‰€ä»¥ç›®å½•ç»“æ„å›ºå®šã€‚
            # datasets.ImageFolder(...)ï¼Œæ˜¯ PyTorch torchvision è‡ªå¸¦çš„ä¸€ä¸ªå·¥å…·ç±»ï¼Œç”¨æ¥ä»æ–‡ä»¶å¤¹é‡ŒåŠ è½½æ•°æ®é›†ã€‚
            # transform=train_transformè¡¨ç¤ºï¼šæ¯æ¬¡ä»è¿™ä¸ªæ•°æ®é›†ä¸­å–å›¾ç‰‡çš„æ—¶å€™ï¼Œ
            # éƒ½ä¼šå…ˆæ‰§è¡Œ train_transformï¼ˆä¹Ÿå°±æ˜¯ç¼©æ”¾ã€ç¿»è½¬ã€æ—‹è½¬ã€äº®åº¦æ‰°åŠ¨ã€å½’ä¸€åŒ–ç­‰å¤„ç†ï¼‰ï¼Œå†æŠŠå¤„ç†åçš„ç»“æœäº¤ç»™æ¨¡å‹ã€‚
            dataset = datasets.ImageFolder(str(self.data_dir), transform=train_transform)
            # å…³äºdataset.classesï¼šImageFolder ä¼šè‡ªåŠ¨è®°å½•ä¸‹æœ‰å“ªäº›ç±»åˆ«ï¼Œå¹¶ä¿å­˜åœ¨ .classes å±æ€§é‡Œã€‚
            # æ¯”å¦‚['stage1_village', 'stage2_attack_menu', 'stage3_battle_scene']ã€‚
            self.class_names = dataset.classes
            self.num_classes = len(self.class_names)
            
            print(f"[INFO] æ‰¾åˆ° {self.num_classes} ä¸ªç±»åˆ«: {self.class_names}")
            print(f"[INFO] æ€»å…± {len(dataset)} å¼ å›¾ç‰‡")
            
            # æ•°æ®åˆ†å‰²
            train_size = int(train_split * len(dataset))
            val_size = len(dataset) - train_size
            # random_split è¿›è¡Œéšæœºåˆ’åˆ†ã€‚
            train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])
            
            # ä¸ºéªŒè¯é›†è®¾ç½®ä¸åŒçš„transformã€‚
            # val_dataset æ˜¯ Subsetï¼Œå®ƒæœ‰ä¸ª .dataset å±æ€§ï¼ŒæŒ‡å‘åŸå§‹ ImageFolder å¯¹è±¡ã€‚
            val_dataset.dataset.transform = val_transform
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            self.train_loader = DataLoader(
                train_dataset, 
                batch_size=self.batch_size, 
                shuffle=True, 
                num_workers=2,
                pin_memory=True if self.device.type == 'cuda' else False
            )
            
            self.val_loader = DataLoader(
                val_dataset, 
                batch_size=self.batch_size, 
                shuffle=False, 
                num_workers=2,
                pin_memory=True if self.device.type == 'cuda' else False
            )
            
            return True
            
        except Exception as e:
            print(f"[ERROR] æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def build_model(self, model_name: str = "resnet18", pretrained: bool = True) -> None:
        """
        æ„å»ºæ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°
            pretrained: æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
        """
        if model_name == "resnet18":
            self.model = models.resnet18(pretrained=pretrained)
            self.model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(self.model.fc.in_features, self.num_classes)
            )
        elif model_name == "resnet50":
            self.model = models.resnet50(pretrained=pretrained)
            self.model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(self.model.fc.in_features, self.num_classes)
            )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
        
        self.model = self.model.to(self.device)
        print(f"[INFO] æ¨¡å‹ {model_name} å·²æ„å»ºå®Œæˆ")
    
    def train_epoch(self, optimizer, criterion, scheduler=None) -> Tuple[float, float]:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (imgs, labels) in enumerate(self.train_loader):
            imgs, labels = imgs.to(self.device), labels.to(self.device)
            
            optimizer.zero_grad()
            outputs = self.model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()
        
        if scheduler:
            scheduler.step()
        
        avg_loss = train_loss / len(self.train_loader)
        accuracy = 100 * train_correct / train_total
        
        return avg_loss, accuracy
    
    def validate_epoch(self, criterion) -> Tuple[float, float]:
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for imgs, labels in self.val_loader:
                imgs, labels = imgs.to(self.device), labels.to(self.device)
                
                outputs = self.model(imgs)
                loss = criterion(outputs, labels)
                
                val_loss += loss.item()
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()
        
        avg_loss = val_loss / len(self.val_loader)
        accuracy = 100 * val_correct / val_total
        
        return avg_loss, accuracy
    
    def train(self, epochs: int = 20, save_best_only: bool = True) -> Dict:
        """
        å¼€å§‹è®­ç»ƒ
        
        Args:
            epochs: è®­ç»ƒè½®æ•°
            save_best_only: æ˜¯å¦åªä¿å­˜æœ€ä½³æ¨¡å‹
            
        Returns:
            Dict: è®­ç»ƒå†å²
        """
        if not self.model:
            raise ValueError("è¯·å…ˆè°ƒç”¨ build_model() æ„å»ºæ¨¡å‹")
        
        # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
        
        best_val_acc = 0.0
        
        print(f"[INFO] å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} ä¸ªepoch")
        print("=" * 60)
        
        for epoch in range(epochs):
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_acc = self.train_epoch(optimizer, criterion, scheduler)
            
            # éªŒè¯é˜¶æ®µ
            val_loss, val_acc = self.validate_epoch(criterion)
            
            # è®°å½•å†å²
            self.training_history["train_loss"].append(train_loss)
            self.training_history["train_acc"].append(train_acc)
            self.training_history["val_loss"].append(val_loss)
            self.training_history["val_acc"].append(val_acc)
            
            # è¾“å‡ºç»“æœ
            print(f"Epoch [{epoch+1}/{epochs}]")
            print(f"  è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
            print(f"  éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.2f}%")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                if save_best_only:
                    self.save_model(val_acc, epoch + 1)
                    print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%)")
            
            print("-" * 40)
        
        print("=" * 60)
        print(f"ğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%")
        
        return self.training_history
    
    def save_model(self, val_acc: float, epoch: int) -> None:
        """ä¿å­˜æ¨¡å‹å’Œé…ç½®"""
        model_data = {
            "model_state": self.model.state_dict(),
            "class_names": self.class_names,
            "num_classes": self.num_classes,
            "val_acc": val_acc,
            "epoch": epoch,
            "img_size": self.img_size,
            "device": str(self.device)
        }
        
        torch.save(model_data, self.model_save_path)
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config = {
            "class_names": self.class_names,
            "num_classes": self.num_classes,
            "img_size": self.img_size,
            "model_path": self.model_save_path,
            "best_val_acc": val_acc,
            "training_epochs": epoch
        }
        
        with open(self.config_save_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        print(f"[INFO] æ¨¡å‹å·²ä¿å­˜: {self.model_save_path}")
        print(f"[INFO] é…ç½®å·²ä¿å­˜: {self.config_save_path}")
    
    def load_model(self, model_path: Optional[str] = None) -> bool:
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            model_path = model_path or self.model_save_path
            
            if not os.path.exists(model_path):
                print(f"[ERROR] æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
            
            model_data = torch.load(model_path, map_location=self.device)
            
            self.class_names = model_data["class_names"]
            self.num_classes = model_data["num_classes"]
            
            # é‡æ–°æ„å»ºæ¨¡å‹
            self.build_model()
            self.model.load_state_dict(model_data["model_state"])
            
            print(f"[INFO] æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
            print(f"[INFO] ç±»åˆ«: {self.class_names}")
            
            return True
            
        except Exception as e:
            print(f"[ERROR] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False


def main():
    """ç¤ºä¾‹ä½¿ç”¨"""
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SceneClassifierTrainer(
        data_dir="../scene_classification_dataset",
        model_save_path="bb_auto_attack/BBAutoAttack_scene_classifier.pt",
        batch_size=16,
        learning_rate=0.001
    )
    
    # åŠ è½½æ•°æ®
    if not trainer.load_data():
        print("æ•°æ®åŠ è½½å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        return
    
    # æ„å»ºæ¨¡å‹
    trainer.build_model(model_name="resnet18", pretrained=True)
    
    # å¼€å§‹è®­ç»ƒ
    history = trainer.train(epochs=20)
    
    print("è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()